{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/Users/yannetinterian/teaching/deep-learning-di/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding is simply converting each value in a column to a number (0 to num_classes).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car (toy) dataset \n",
    "https://archive.ics.uci.edu/ml/datasets/Car+Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(PATH/\"cars/car.data\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'unacc', 'unacc', ..., 'unacc', 'good', 'vgood'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.iloc[:, 6].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5\n",
       "0  vhigh  vhigh  2  2  small   low\n",
       "1  vhigh  vhigh  2  2  small   med\n",
       "2  vhigh  vhigh  2  2  small  high\n",
       "3  vhigh  vhigh  2  2    med   low\n",
       "4  vhigh  vhigh  2  2    med   med"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2     3      4     5\n",
       "1223    med    low      3     2    big  high\n",
       "1517    low    med      2     2    med  high\n",
       "126   vhigh   high      2  more  small   low\n",
       "1715    low    low  5more     4    med  high\n",
       "58    vhigh  vhigh      4     2    med   med"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    object\n",
       "1    object\n",
       "2    object\n",
       "3    object\n",
       "4    object\n",
       "5    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannetinterian/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/yannetinterian/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train.dtypes[col] == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_val[col] = le.transform(X_val[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 2, 3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "1223  2  1  1  0  0  0\n",
       "1517  1  2  0  0  1  0\n",
       "126   3  0  0  2  2  1\n",
       "1715  1  1  3  1  1  0\n",
       "58    3  3  2  0  1  2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "350   3  1  0  2  0  0\n",
       "112   3  0  0  0  1  2\n",
       "1011  2  0  1  1  1  1\n",
       "715   0  2  2  1  1  2\n",
       "1280  2  1  3  1  2  0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 6)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3]),\n",
       " array([0, 1, 2, 3]),\n",
       " array([0, 1, 2, 3]),\n",
       " array([0, 1, 2]),\n",
       " array([0, 1, 2]),\n",
       " array([0, 1, 2])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.unique(X_train[col].values) for col in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 3, 3, 3]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_levels = [len(np.unique(X_train[col].values)) for col in X_train]\n",
    "cat_levels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "Most deep learning models use a dense vectors of real numbers as representation of words or categorical variables, as opposed to a one-hot encoding representations. The module torch.nn.Embedding is used to represent word embeddings. It takes two arguments: number of levels in your categorical variable, and the dimensionality of the embeddings. The embeddings are initialized with random vectors and are learned in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2362, -1.1640,  1.4995, -0.1408,  0.9529],\n",
       "        [-1.5915,  0.3404, -2.1976, -0.1452,  0.7634],\n",
       "        [-0.7736, -1.2214, -1.9864, -0.1815, -0.4461],\n",
       "        [ 0.3987,  1.2341,  0.3971,  0.2056,  0.5141]], requires_grad=True)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An Embedding layer containing 4 categories and embedding size 5. \n",
    "# Embeddings will be initialized at random.\n",
    "embed = nn.Embedding(4, 5)\n",
    "embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5915,  0.3404, -2.1976, -0.1452,  0.7634],\n",
       "        [-0.2362, -1.1640,  1.4995, -0.1408,  0.9529],\n",
       "        [-1.5915,  0.3404, -2.1976, -0.1452,  0.7634],\n",
       "        [ 0.3987,  1.2341,  0.3971,  0.2056,  0.5141],\n",
       "        [ 0.3987,  1.2341,  0.3971,  0.2056,  0.5141],\n",
       "        [-0.7736, -1.2214, -1.9864, -0.1815, -0.4461]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each categotical variable with K levels should be relabel with levels between 0 and K-1.\n",
    "# Given a coulmn x, to \"look up\" the embedding of each level do:\n",
    "# Note that it needs type LongTensor\n",
    "x = torch.LongTensor([1, 0, 1, 3, 3 , 2])\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, cat_levels, emb_size=5, n_class=4):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, emb_size) for c in cat_levels])\n",
    "        self.lin1 = nn.Linear(6*emb_size, 20)\n",
    "        self.lin2 = nn.Linear(20, n_class)\n",
    "        self.bn = nn.BatchNorm1d(20)\n",
    "        self.emb_drop = nn.Dropout(0.1)\n",
    "        self.drops = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # try to write a shorter code\n",
    "        e0 = self.embs[0](x[:,0])\n",
    "        e1 = self.embs[1](x[:,1])\n",
    "        e2 = self.embs[2](x[:,2])\n",
    "        e3 = self.embs[3](x[:,3])\n",
    "        e4 = self.embs[4](x[:,4])\n",
    "        e5 = self.embs[5](x[:,5])\n",
    "        x = torch.cat([e0, e1, e2, e3, e4, e5], 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(cat_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.LongTensor(X_train.values)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, epochs=5):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        out = model(x_train)\n",
    "        loss = F.cross_entropy(out, y_train)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        val_loss, val_acc = val_metric(model)\n",
    "        if i % 15 == 0: \n",
    "            print(\"train loss %.3f val loss %.3f and accuracy %.3f\" % (loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = torch.LongTensor(X_val.values)\n",
    "y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metric(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    out = model(x_val)\n",
    "    loss = F.cross_entropy(out, y_val)\n",
    "    pred = torch.max(out, 1)[1]\n",
    "    correct += (pred == y_val).float().sum().item()\n",
    "    return loss, correct/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(cat_levels)\n",
    "optim = get_optimizer(model, lr = 0.01, wd = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.495 val loss 1.380 and accuracy 0.344\n",
      "train loss 0.625 val loss 0.581 and accuracy 0.824\n",
      "train loss 0.288 val loss 0.253 and accuracy 0.910\n",
      "train loss 0.210 val loss 0.165 and accuracy 0.948\n",
      "train loss 0.183 val loss 0.118 and accuracy 0.971\n",
      "train loss 0.131 val loss 0.099 and accuracy 0.980\n",
      "train loss 0.131 val loss 0.091 and accuracy 0.977\n",
      "train loss 0.127 val loss 0.074 and accuracy 0.977\n",
      "train loss 0.105 val loss 0.077 and accuracy 0.974\n",
      "train loss 0.113 val loss 0.065 and accuracy 0.980\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optim, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WiDS 2018  dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this part of the notebook comes from this kaggle [competition](https://www.kaggle.com/c/wids2018datathon/). You are given a dataset of survey questions and results from a developing country. Your goal is to predict the gender of the respondent based on the other answers he/she provided. You Kaggle api to get the data. All variables in this dataset and categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install kaggle` <br/>\n",
    "\n",
    "`kaggle competitions download -c wids2018datathon -p /path/to/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  ...  \\\n",
       "0         0    3   32  3.0  NaN  323011  3854   481  1975          1  ...   \n",
       "1         1    2   26  NaN  8.0  268131  2441   344  1981          1  ...   \n",
       "2         2    1   16  NaN  7.0  167581   754   143  1995          1  ...   \n",
       "3         3    4   44  5.0  NaN  445071  5705   604  1980          1  ...   \n",
       "4         4    4   43  NaN  6.0  436161  5645   592  1958          1  ...   \n",
       "\n",
       "    GN1  GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0         NaN  99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN         NaN   1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN         NaN   2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1235 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH/\"train.csv\", low_memory=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1235)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3  ...   GN1  \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3  ...  99.0   \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8  ...   NaN   \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3  ...   1.0   \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3  ...   NaN   \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3  ...   NaN   \n",
       "\n",
       "  GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train id looks like a unique id for each row\n",
    "train = train.drop(columns=[\"train_id\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns with too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"AA5\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA3                     0\n",
       "AA4                     0\n",
       "AA5                 12602\n",
       "AA6                  5653\n",
       "AA7                     0\n",
       "AA14                    0\n",
       "AA15                    0\n",
       "DG1                     0\n",
       "is_female               0\n",
       "DG3                     0\n",
       "DG3A                    0\n",
       "DG3A_OTHERS         18205\n",
       "DG4                     0\n",
       "DG4_OTHERS          18255\n",
       "DG5_1                   0\n",
       "DG5_2                   0\n",
       "DG5_3                   0\n",
       "DG5_4                   0\n",
       "DG5_5                   0\n",
       "DG5_6                   0\n",
       "DG5_7                   0\n",
       "DG5_8                   0\n",
       "DG5_9                   0\n",
       "DG5_10                  0\n",
       "DG5_11                  0\n",
       "DG5_96                  0\n",
       "DG6                     0\n",
       "DG8a                    0\n",
       "DG8b                    0\n",
       "DG8c                    0\n",
       "                    ...  \n",
       "FB28_2_OTHERS       18253\n",
       "FB28_3_OTHERS       18255\n",
       "FB28_4_OTHERS       18253\n",
       "FB28_96_OTHERS      18254\n",
       "FB29_1                  0\n",
       "FB29_2                  0\n",
       "FB29_3                  0\n",
       "FB29_4                  0\n",
       "FB29_5                  0\n",
       "FB29_6                  0\n",
       "FB29_96                 0\n",
       "FB29_OTHERS         18189\n",
       "LN1A                    0\n",
       "LN1B                    0\n",
       "LN2_1                   0\n",
       "LN2_2                   0\n",
       "LN2_3                   0\n",
       "LN2_4                   0\n",
       "LN2_RIndLngBEOth     6914\n",
       "LN2_WIndLngBEOth     6911\n",
       "GN1                  4025\n",
       "GN1_OTHERS          18196\n",
       "GN2                     0\n",
       "GN2_OTHERS          18177\n",
       "GN3                     0\n",
       "GN3_OTHERS          18172\n",
       "GN4                     0\n",
       "GN4_OTHERS          18169\n",
       "GN5                     0\n",
       "GN5_OTHERS          18179\n",
       "Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of NULL in per column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping columns with too many nulls\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() > 12000:\n",
    "        #print(col, train[col].isnull().sum())\n",
    "        train.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  is_female  DG3  DG3A  ...  LN2_2  \\\n",
       "0    3   32  NaN  323011  3854   481  1975          1    3     4  ...      1   \n",
       "1    2   26  8.0  268131  2441   344  1981          1    8     4  ...      1   \n",
       "2    1   16  7.0  167581   754   143  1995          1    3     2  ...      1   \n",
       "3    4   44  NaN  445071  5705   604  1980          1    3     4  ...      1   \n",
       "4    4   43  6.0  436161  5645   592  1958          1    3     4  ...      4   \n",
       "\n",
       "   LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1  GN2  GN3  GN4  GN5  \n",
       "0      1      1               NaN               NaN  99.0   99   99   99   99  \n",
       "1      3      4           Bengali           Bengali   NaN    1    2    2    2  \n",
       "2      2      2             Hindi             Hindi   1.0    2    2    2    2  \n",
       "3      4      5             Tamil             Tamil   NaN    2    2   99   99  \n",
       "4      4      4         Malayalam         Malayalam   NaN    1    1    1    1  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just kept 421 columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 421)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a csv\n",
    "train.to_csv(PATH/\"train_421_cols.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH/\"train_421_cols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the label into another variable, dropping from main dataframe\n",
    "Y = train[\"is_female\"].values.astype(np.float32)\n",
    "X = train.drop(columns=[\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NAs and doing label encoding\n",
    "# Label encoding is simply converting each value in a column to a number (0 to num_classes).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in X.columns:\n",
    "    if X.dtypes[col] == \"object\":\n",
    "        X[col] = X[col].fillna(\"NA\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(0)\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# telling pandas that all the variables are categorical\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>482</td>\n",
       "      <td>252</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>410</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>310</td>\n",
       "      <td>166</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13476</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>664</td>\n",
       "      <td>564</td>\n",
       "      <td>300</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13406</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>587</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA3 AA4 AA6  AA7 AA14 AA15 DG1 DG3 DG3A DG4  ... LN2_2 LN2_3 LN2_4  \\\n",
       "11369   1  10   2  424  482  252  62   2    3   4  ...     0     0     0   \n",
       "1250    2  17   1  831  831  410  63   2    3   5  ...     0     3     3   \n",
       "7527    1   8   0  301  310  166  53   2    3   0  ...     0     0     0   \n",
       "13476   2  14   2  664  564  300  69   2    3   4  ...     2     2     2   \n",
       "13406   0  12   3  587  111   76  58   2    3   2  ...     1     3     3   \n",
       "\n",
       "      LN2_RIndLngBEOth LN2_WIndLngBEOth GN1 GN2 GN3 GN4 GN5  \n",
       "11369               38               38   0   1   1   1   1  \n",
       "1250                33               32   1   2   2   0   0  \n",
       "7527                38               38   2   1   1   1   1  \n",
       "13476               14               14   3   2   2   2   2  \n",
       "13406               14               14   1   0   2   2   2  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA3': 4,\n",
       " 'AA4': 22,\n",
       " 'AA6': 4,\n",
       " 'AA7': 1050,\n",
       " 'AA14': 907,\n",
       " 'AA15': 450,\n",
       " 'DG1': 79,\n",
       " 'DG3': 9,\n",
       " 'DG3A': 8,\n",
       " 'DG4': 12,\n",
       " 'DG6': 9,\n",
       " 'DG8a': 13,\n",
       " 'DG8b': 13,\n",
       " 'DG8c': 13,\n",
       " 'DG9a': 12,\n",
       " 'DG9b': 11,\n",
       " 'DG9c': 8,\n",
       " 'DG10b': 9,\n",
       " 'DG10c': 8,\n",
       " 'DG11b': 9,\n",
       " 'DL1': 12,\n",
       " 'DL2': 33,\n",
       " 'DL3': 3,\n",
       " 'DL5': 25,\n",
       " 'DL7': 3,\n",
       " 'DL8': 342,\n",
       " 'DL11': 15,\n",
       " 'DL14': 24,\n",
       " 'DL15': 4,\n",
       " 'DL24': 7,\n",
       " 'MT1': 13,\n",
       " 'MT1A': 8,\n",
       " 'MT3_1': 5,\n",
       " 'MT3_2': 6,\n",
       " 'MT3_3': 6,\n",
       " 'MT4_1': 3,\n",
       " 'MT4_2': 3,\n",
       " 'MT4_3': 3,\n",
       " 'MT4_4': 3,\n",
       " 'MT4_5': 3,\n",
       " 'MT4_6': 3,\n",
       " 'MT5': 8,\n",
       " 'MT6': 10,\n",
       " 'MT6A': 7,\n",
       " 'MT6B': 9,\n",
       " 'MT6C': 28,\n",
       " 'MT7': 3,\n",
       " 'MT11': 83,\n",
       " 'MT12_1': 5,\n",
       " 'MT12_2': 7,\n",
       " 'MT12_3': 6,\n",
       " 'MT12_4': 3,\n",
       " 'MT12_5': 3,\n",
       " 'MT12_7': 5,\n",
       " 'MT12_9': 3,\n",
       " 'MT12_11': 5,\n",
       " 'MT12_12': 3,\n",
       " 'MT12_13': 3,\n",
       " 'MT12_14': 3,\n",
       " 'MT14C_1': 5,\n",
       " 'MT14C_2': 5,\n",
       " 'MT14C_3': 5,\n",
       " 'MT14C_4': 5,\n",
       " 'MT15': 3,\n",
       " 'MT17_1': 7,\n",
       " 'MT17_2': 7,\n",
       " 'MT17_3': 7,\n",
       " 'MT17_4': 7,\n",
       " 'MT17_5': 7,\n",
       " 'MT17_6': 7,\n",
       " 'MT17_7': 7,\n",
       " 'MT17_8': 7,\n",
       " 'MT17_9': 7,\n",
       " 'MT17_10': 7,\n",
       " 'MT17_11': 7,\n",
       " 'MT17_12': 7,\n",
       " 'MT17_13': 7,\n",
       " 'MT18_1': 3,\n",
       " 'MT18_2': 3,\n",
       " 'MT18_3': 3,\n",
       " 'MT18_4': 3,\n",
       " 'MT18_5': 3,\n",
       " 'MT18_6': 3,\n",
       " 'MT18_96': 3,\n",
       " 'MT18_8': 3,\n",
       " 'FF2': 4,\n",
       " 'FF2A': 18,\n",
       " 'FF3': 27,\n",
       " 'FF4': 3,\n",
       " 'FF5': 4,\n",
       " 'FF6_1': 4,\n",
       " 'FF6_2': 4,\n",
       " 'FF6_3': 4,\n",
       " 'FF6_4': 4,\n",
       " 'FF6_5': 4,\n",
       " 'FF6_6': 4,\n",
       " 'FF6_7': 4,\n",
       " 'FF6_8': 4,\n",
       " 'FF6_9': 4,\n",
       " 'FF6_10': 4,\n",
       " 'FF7_1': 4,\n",
       " 'FF7_2': 4,\n",
       " 'FF7_4': 5,\n",
       " 'FF7_5': 4,\n",
       " 'FF7_6': 3,\n",
       " 'FF9': 7,\n",
       " 'FF10_1': 3,\n",
       " 'FF10_2': 3,\n",
       " 'FF10_3': 3,\n",
       " 'FF10_4': 3,\n",
       " 'FF10_5': 3,\n",
       " 'FF10_6': 3,\n",
       " 'FF10_96': 3,\n",
       " 'FF13': 8,\n",
       " 'FF14_1': 3,\n",
       " 'FF14_2': 3,\n",
       " 'FF14_3': 3,\n",
       " 'FF14_4': 3,\n",
       " 'FF14_5': 3,\n",
       " 'FF14_6': 3,\n",
       " 'FF14_7': 3,\n",
       " 'FF14_8': 3,\n",
       " 'FF14_9': 3,\n",
       " 'FF14_10': 3,\n",
       " 'FF14_11': 3,\n",
       " 'FF14_12': 3,\n",
       " 'FF14_13': 3,\n",
       " 'FF14_14': 3,\n",
       " 'FF14_15': 3,\n",
       " 'FF14_16': 3,\n",
       " 'FF14_17': 3,\n",
       " 'FF14_18': 3,\n",
       " 'FF14_19': 3,\n",
       " 'FF14_20': 3,\n",
       " 'FF14_21': 3,\n",
       " 'FF14_22': 3,\n",
       " 'FF14_23': 3,\n",
       " 'FF14_96': 3,\n",
       " 'FF16_1': 6,\n",
       " 'FF16_2': 6,\n",
       " 'FF19_1': 3,\n",
       " 'FF19_2': 3,\n",
       " 'FF19_3': 3,\n",
       " 'FF19_4': 3,\n",
       " 'FF19_5': 3,\n",
       " 'FF19_6': 3,\n",
       " 'FF19_7': 3,\n",
       " 'FF19_8': 3,\n",
       " 'MM3_1': 3,\n",
       " 'MM3_2': 3,\n",
       " 'MM3_3': 3,\n",
       " 'MM3_4': 3,\n",
       " 'MM3_5': 3,\n",
       " 'MM3_6': 3,\n",
       " 'MM3_7': 3,\n",
       " 'MM3_8': 3,\n",
       " 'MM3_9': 3,\n",
       " 'MM3_10': 3,\n",
       " 'MM3_11': 3,\n",
       " 'MM3_12': 3,\n",
       " 'MM3_13': 3,\n",
       " 'MM3_14': 3,\n",
       " 'IFI14_1': 7,\n",
       " 'IFI14_2': 7,\n",
       " 'IFI14_3': 7,\n",
       " 'IFI14_4': 7,\n",
       " 'IFI14_5': 7,\n",
       " 'IFI14_6': 7,\n",
       " 'IFI14_7': 7,\n",
       " 'IFI15_1': 7,\n",
       " 'IFI15_2': 7,\n",
       " 'IFI15_3': 7,\n",
       " 'IFI15_4': 7,\n",
       " 'IFI15_5': 7,\n",
       " 'IFI15_6': 7,\n",
       " 'IFI15_7': 7,\n",
       " 'IFI16_1': 11,\n",
       " 'IFI16_2': 11,\n",
       " 'IFI17_1': 7,\n",
       " 'IFI17_2': 7,\n",
       " 'IFI18': 9,\n",
       " 'IFI24': 12,\n",
       " 'FL1': 4,\n",
       " 'FL2': 5,\n",
       " 'FL3': 10,\n",
       " 'FL4': 19,\n",
       " 'FL7_1': 3,\n",
       " 'FL7_2': 3,\n",
       " 'FL7_3': 3,\n",
       " 'FL7_4': 3,\n",
       " 'FL7_5': 3,\n",
       " 'FL7_6': 3,\n",
       " 'FL8_1': 5,\n",
       " 'FL8_2': 5,\n",
       " 'FL8_3': 5,\n",
       " 'FL8_4': 5,\n",
       " 'FL8_5': 5,\n",
       " 'FL8_6': 5,\n",
       " 'FL8_7': 5,\n",
       " 'FL9A': 12,\n",
       " 'FL9B': 13,\n",
       " 'FL9C': 13,\n",
       " 'FL10': 13,\n",
       " 'FL11': 5,\n",
       " 'FL12': 3,\n",
       " 'FL14': 3,\n",
       " 'FL15': 4,\n",
       " 'FL16': 3,\n",
       " 'FL17': 3,\n",
       " 'FL18': 3,\n",
       " 'FB2': 3,\n",
       " 'FB13': 25,\n",
       " 'FB18': 5,\n",
       " 'FB19': 11,\n",
       " 'FB19B_1': 4,\n",
       " 'FB19B_2': 4,\n",
       " 'FB19B_3': 4,\n",
       " 'FB19B_4': 4,\n",
       " 'FB19B_5': 4,\n",
       " 'FB19B_96': 4,\n",
       " 'FB20': 16,\n",
       " 'FB24': 17,\n",
       " 'FB26_1': 3,\n",
       " 'FB26_2': 3,\n",
       " 'FB26_3': 3,\n",
       " 'FB26_4': 3,\n",
       " 'FB26_5': 3,\n",
       " 'FB26_6': 3,\n",
       " 'FB26_7': 3,\n",
       " 'FB26_8': 3,\n",
       " 'FB26_9': 3,\n",
       " 'FB26_10': 3,\n",
       " 'FB26_11': 3,\n",
       " 'FB26_96': 3,\n",
       " 'FB26_99': 3,\n",
       " 'LN1A': 4,\n",
       " 'LN1B': 4,\n",
       " 'LN2_1': 5,\n",
       " 'LN2_2': 5,\n",
       " 'LN2_3': 5,\n",
       " 'LN2_4': 5,\n",
       " 'LN2_RIndLngBEOth': 58,\n",
       " 'LN2_WIndLngBEOth': 59,\n",
       " 'GN1': 7,\n",
       " 'GN2': 6,\n",
       " 'GN3': 6,\n",
       " 'GN4': 6,\n",
       " 'GN5': 6}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables with two values are fine \n",
    "# number of values for variables with more than 2 values\n",
    "emb_c = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\n",
    "emb_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2),\n",
       " (22, 11),\n",
       " (4, 2),\n",
       " (1050, 50),\n",
       " (907, 50),\n",
       " (450, 50),\n",
       " (79, 40),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (12, 6),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (12, 6),\n",
       " (11, 6),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (33, 17),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (3, 2),\n",
       " (342, 50),\n",
       " (15, 8),\n",
       " (24, 12),\n",
       " (4, 2),\n",
       " (7, 4),\n",
       " (13, 7),\n",
       " (8, 4),\n",
       " (5, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (10, 5),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (28, 14),\n",
       " (3, 2),\n",
       " (83, 42),\n",
       " (5, 3),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (18, 9),\n",
       " (27, 14),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (11, 6),\n",
       " (11, 6),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (10, 5),\n",
       " (19, 10),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (12, 6),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (5, 3),\n",
       " (11, 6),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (16, 8),\n",
       " (17, 9),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (58, 29),\n",
       " (59, 30),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the category, size of the embedding\n",
    "# 30 and (c+1)//2) are arbitrary (we should play with these numbers)\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in emb_c.items()]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AA3', 'AA4', 'AA6', 'AA7', 'AA14', 'AA15', 'DG1', 'DG3', 'DG3A', 'DG4', 'DG6', 'DG8a', 'DG8b', 'DG8c', 'DG9a', 'DG9b', 'DG9c', 'DG10b', 'DG10c', 'DG11b', 'DL1', 'DL2', 'DL3', 'DL5', 'DL7', 'DL8', 'DL11', 'DL14', 'DL15', 'DL24', 'MT1', 'MT1A', 'MT3_1', 'MT3_2', 'MT3_3', 'MT4_1', 'MT4_2', 'MT4_3', 'MT4_4', 'MT4_5', 'MT4_6', 'MT5', 'MT6', 'MT6A', 'MT6B', 'MT6C', 'MT7', 'MT11', 'MT12_1', 'MT12_2', 'MT12_3', 'MT12_4', 'MT12_5', 'MT12_7', 'MT12_9', 'MT12_11', 'MT12_12', 'MT12_13', 'MT12_14', 'MT14C_1', 'MT14C_2', 'MT14C_3', 'MT14C_4', 'MT15', 'MT17_1', 'MT17_2', 'MT17_3', 'MT17_4', 'MT17_5', 'MT17_6', 'MT17_7', 'MT17_8', 'MT17_9', 'MT17_10', 'MT17_11', 'MT17_12', 'MT17_13', 'MT18_1', 'MT18_2', 'MT18_3', 'MT18_4', 'MT18_5', 'MT18_6', 'MT18_96', 'MT18_8', 'FF2', 'FF2A', 'FF3', 'FF4', 'FF5', 'FF6_1', 'FF6_2', 'FF6_3', 'FF6_4', 'FF6_5', 'FF6_6', 'FF6_7', 'FF6_8', 'FF6_9', 'FF6_10', 'FF7_1', 'FF7_2', 'FF7_4', 'FF7_5', 'FF7_6', 'FF9', 'FF10_1', 'FF10_2', 'FF10_3', 'FF10_4', 'FF10_5', 'FF10_6', 'FF10_96', 'FF13', 'FF14_1', 'FF14_2', 'FF14_3', 'FF14_4', 'FF14_5', 'FF14_6', 'FF14_7', 'FF14_8', 'FF14_9', 'FF14_10', 'FF14_11', 'FF14_12', 'FF14_13', 'FF14_14', 'FF14_15', 'FF14_16', 'FF14_17', 'FF14_18', 'FF14_19', 'FF14_20', 'FF14_21', 'FF14_22', 'FF14_23', 'FF14_96', 'FF16_1', 'FF16_2', 'FF19_1', 'FF19_2', 'FF19_3', 'FF19_4', 'FF19_5', 'FF19_6', 'FF19_7', 'FF19_8', 'MM3_1', 'MM3_2', 'MM3_3', 'MM3_4', 'MM3_5', 'MM3_6', 'MM3_7', 'MM3_8', 'MM3_9', 'MM3_10', 'MM3_11', 'MM3_12', 'MM3_13', 'MM3_14', 'IFI14_1', 'IFI14_2', 'IFI14_3', 'IFI14_4', 'IFI14_5', 'IFI14_6', 'IFI14_7', 'IFI15_1', 'IFI15_2', 'IFI15_3', 'IFI15_4', 'IFI15_5', 'IFI15_6', 'IFI15_7', 'IFI16_1', 'IFI16_2', 'IFI17_1', 'IFI17_2', 'IFI18', 'IFI24', 'FL1', 'FL2', 'FL3', 'FL4', 'FL7_1', 'FL7_2', 'FL7_3', 'FL7_4', 'FL7_5', 'FL7_6', 'FL8_1', 'FL8_2', 'FL8_3', 'FL8_4', 'FL8_5', 'FL8_6', 'FL8_7', 'FL9A', 'FL9B', 'FL9C', 'FL10', 'FL11', 'FL12', 'FL14', 'FL15', 'FL16', 'FL17', 'FL18', 'FB2', 'FB13', 'FB18', 'FB19', 'FB19B_1', 'FB19B_2', 'FB19B_3', 'FB19B_4', 'FB19B_5', 'FB19B_96', 'FB20', 'FB24', 'FB26_1', 'FB26_2', 'FB26_3', 'FB26_4', 'FB26_5', 'FB26_6', 'FB26_7', 'FB26_8', 'FB26_9', 'FB26_10', 'FB26_11', 'FB26_96', 'FB26_99', 'LN1A', 'LN1B', 'LN2_1', 'LN2_2', 'LN2_3', 'LN2_4', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth', 'GN1', 'GN2', 'GN3', 'GN4', 'GN5'])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_cols = emb_c.keys()\n",
    "emb_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset is a custom class to conveniently interact with a set observations. Designing this Dataset class is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variables are categorical, but some of them has just two values \n",
    "# emb_c are the variables we plan to embed\n",
    "class WiDSDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        # splitting categorical columns and numerical columns\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X1[idx], self.X2[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WiDSDataset(X_train, y_train, emb_cols)\n",
    "valid_ds = WiDSDataset(X_val, y_val, emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   4,   3, 200, 229, 129,  72,   0,   3,   5,   2,   5,   3,\n",
       "          1,   3,   0,   0,   3,   0,   3,   5,   0,   0,   0,   1, 136,\n",
       "          0,   8,   3,   0,   1,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,   1,   3,\n",
       "          1,   3,   2,   1,   2,   3,   2,   2,   2,   0,   0,   1,   0,\n",
       "          0,   4,   1,   2,   2,   2,   2,   2,   2,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   0,   2,   2,   6,   6,   6,   6,   6,   6,\n",
       "          1,   6,   6,   6,   6,   6,   6,   6,   0,   1,   0,   8,   0,\n",
       "          3,   0,   0,   7,   1,   1,   1,   1,   1,   1,   1,   3,   2,\n",
       "          1,   1,   3,   2,  10,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          0,   0,   1,  24,   4,   9,   3,   2,   2,   2,   2,   2,  15,\n",
       "          0,   2,   2,   2,   2,   1,   1,   1,   1,   2,   2,   1,   2,\n",
       "          2,   1,   1,   0,   0,   3,   3,  14,  14,   0,   2,   2,   3,\n",
       "          2]),\n",
       " array([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " 0.0]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from fast.ai\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs) \n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
    "        self.lin2 = nn.Linear(100, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.5)\n",
    "        self.drops = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 248]) torch.Size([5, 172]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x1, x2, y = next(iter(train_dl))\n",
    "print(x1.shape, x2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7157],\n",
       "        [-0.0512],\n",
       "        [-0.1596],\n",
       "        [ 0.4292],\n",
       "        [-0.4400]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "out = model(x1, x2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (out > 0.0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == y).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7673, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl=train_dl, verbose=False):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for i, (x1, x2, y) in enumerate(train_dl):\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)  \n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        if verbose: print(sum_loss/total)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)\n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = (out > 0).float()\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"val loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"loss \", loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the higest learning rate that doesn't cycle \n",
    "#optim = get_optimizer(model, lr = 0.1, wd = 0.0)\n",
    "#train_model(model, optim, train_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  0.4143321806112403\n",
      "val loss 0.284 and accuracy 0.882\n",
      "loss  0.2807229181587843\n",
      "val loss 0.257 and accuracy 0.893\n",
      "loss  0.25467434769557035\n",
      "val loss 0.249 and accuracy 0.898\n",
      "loss  0.2318686624849636\n",
      "val loss 0.246 and accuracy 0.900\n",
      "loss  0.22278552754827802\n",
      "val loss 0.244 and accuracy 0.906\n",
      "loss  0.21738180170007615\n",
      "val loss 0.255 and accuracy 0.903\n",
      "loss  0.2165544631505006\n",
      "val loss 0.248 and accuracy 0.902\n",
      "loss  0.19747614373216496\n",
      "val loss 0.255 and accuracy 0.907\n",
      "loss  0.1982484082960488\n",
      "val loss 0.267 and accuracy 0.897\n",
      "loss  0.1951014477687155\n",
      "val loss 0.266 and accuracy 0.899\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=10, lr=0.05, wd=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate (LR) range test\n",
    "The [learning rate range test](https://arxiv.org/abs/1506.01186) is a way to estimate minimum and maximum boundary values for learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=1, epochs=2):\n",
    "    losses = []\n",
    "    p = PATH/\"mode_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for j, (x1, x2, y) in enumerate(train_dl):\n",
    "            # changing learning rate at each iteration\n",
    "            optim = get_optimizer(model, lr=lrs[ind])\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            ind +=1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_low, lr_high and batch_size are important so that the plot gives\n",
    "# useful information\n",
    "lrs, losses = LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the lower boundary as the value of the learning rate when the loss starts to decrease. Pick the upper learning rate when the loss slows, becomes ragged or increases. From this graph I would try $base\\_lr=1e-5$ and $max\\_lr=0.075$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/25, max_lr/(25*1e4)\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2000\n",
    "lr = get_cosine_triangular_lr(0.001, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy(model, train_dl, valid_dl, max_lr=0.01, epochs=4):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x1, x2, y) in enumerate(train_dl):\n",
    "            optim = get_optimizer(model, lr = lrs[idx], wd = 0.00001)\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y) \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        print(\"train loss\", sum_loss/total)\n",
    "        val_loss(model, valid_dl)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a new model\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.4420340150080456\n",
      "val loss 0.348 and accuracy 0.854\n",
      "train loss 0.3812336492737624\n",
      "val loss 0.354 and accuracy 0.856\n",
      "train loss 0.3949464450581895\n",
      "val loss 0.324 and accuracy 0.872\n",
      "train loss 0.40260836935898797\n",
      "val loss 0.272 and accuracy 0.882\n",
      "train loss 0.3751502594403194\n",
      "val loss 0.279 and accuracy 0.888\n",
      "train loss 0.3277132433184334\n",
      "val loss 0.260 and accuracy 0.893\n",
      "train loss 0.2839590787103946\n",
      "val loss 0.251 and accuracy 0.897\n",
      "train loss 0.25408555237896246\n",
      "val loss 0.231 and accuracy 0.910\n",
      "train loss 0.2409815379231964\n",
      "val loss 0.228 and accuracy 0.910\n",
      "train loss 0.23372027167340756\n",
      "val loss 0.225 and accuracy 0.911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23372027167340756"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy(model, train_dl, valid_dl, max_lr=0.08, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the toy dataset, get a test score using the test dataset.\n",
    "2. For the second model, get a better validation score by hyper-parameter tunning.\n",
    "3. Find a tabular dataset and create your own model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
